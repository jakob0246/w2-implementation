import os
import torch
import numpy as np
from tqdm import tqdm
from scipy.special import softmax

from .utils.trainer import train
from .utils.evaluator import evaluate
from .utils.unet import UNet
from .utils.utils import InMemoryDataset


def estimate_uncertainty(teacher_model, images, preprocess, postprocess, num_students, num_epochs, num_classes,
                         train_images, preprocess_train, train_params, collate_fn, model_saves_directory):
    """
    Applies student ensemble uncertainty estimation to given images.
    The approach is based on the idea of knowledge distillation. Student models have a UNet architecture.

    Parameters
    ----------
    teacher_model : torch.nn.Module
        A pre-trained convolutional network model that serves as the basis for the training of the student models.
    images : tensor
        A pytorch tensor of shape (#Images, #Channels, N, M).
    preprocess : callable
        A function being in the form of `(tensor) -> (tensor)`.
    postprocess : callable
        Should have the form `(tensor) -> (tensor)`.
    num_students : int
        The number of students scrutinized for the uncertainty estimation.
    num_epochs : int
        Number of training epochs for the students.
    num_classes : int
        The number of classes of the labels.
    train_images : tensor
        A pytorch tensor of shape (#Images, #Channels, N, M).
    preprocess_train : callable
        A function similar to `preprocess`, but not for evaluation images, but for training data (images + labels).
        Should have the signature `(list((tensor, tensor))) -> (list((tensor, tensor)))`.
    train_params : dict
        Should have the following keys:
            "optimizer" (e.g. torch.optim.AdamW), "lr", "batch_size", "weight" (optional),
            "scheduler" (optional, e.g. torch.optim.lr_scheduler.CosineAnnealingWarmRestarts),
            "ignore_label_index" (optional), "scheduler_T_0" (optional), and "scheduler_T_mult" (optional).
    collate_fn : callable, optional
        Collate function for evaluating the model.
        Should be empty most of the time for standard use-cases.
    model_saves_directory : str
        Path to the student model saves.

    Returns
    -------
    model_outputs : list
        A list of length #Samples of model output logits of shape (#Images, #Classes, N, M).
    """

    model_saves_filename = f"student_{num_epochs}_epochs.pt"

    batch_size = train_params.get("batch_size") if train_params.get("batch_size") is not None else 24
    use_dropout = train_params.get("use_dropout") if train_params.get("use_dropout") is not None else True
    use_group_norm = train_params.get("use_group_norm") if train_params.get("use_group_norm") is not None else False
    temperature = train_params.get("temperature") if train_params.get("temperature") is not None else 1.0

    num_channels = images[0].shape[0] if images[0].shape[0] != images[0].shape[1] else images[0].shape[2]

    # Already pre-trained student models are detected automatically
    pretrained = _search_for_pretrained_students(model_saves_directory, model_saves_filename, num_students)

    # Get student model ensemble, either train one or load an existing set
    student_model_ensemble = []
    if not pretrained:
        for i in range(num_students):
            tqdm.write(f"\nTraining student model {i + 1}/{num_students} ...")

            # Build dataloader where images are from the train set and labels are generated by
            # evaluating the teacher model
            teacher_outputs_train_dataset = (
                _build_dataset_from_evaluating_model(teacher_model, train_images, preprocess,
                                                     postprocess, preprocess_train, collate_fn,
                                                     train_params.get("ignore_masks_train_imgs"), temperature))
            teacher_outputs_train_loader = torch.utils.data.DataLoader(teacher_outputs_train_dataset,
                                                                       batch_size=batch_size,
                                                                       shuffle=True, num_workers=1,
                                                                       pin_memory=True)

            model = UNet(num_classes, n_channels=num_channels, use_dropout=use_dropout,
                         use_group_norm=use_group_norm).cuda()
            train(model, teacher_outputs_train_loader, num_epochs, num_classes, train_params)

            model_saves_path = os.path.join(model_saves_directory, f"{i + 1}_{model_saves_filename}")
            torch.save(model.state_dict(), model_saves_path)

            student_model_ensemble.append(model)

    else:
        print()
        for i in range(num_students):
            model_saves_path = os.path.join(model_saves_directory, f"{i + 1}_{model_saves_filename}")
            if os.path.exists(model_saves_path):
                tqdm.write(f"Pretrained student model {i + 1}/{num_students} found, loading model ...")

                model = UNet(num_classes, n_channels=num_channels, use_dropout=use_dropout,
                             use_group_norm=use_group_norm).cuda()
                model.load_state_dict(torch.load(model_saves_path, map_location=torch.device("cuda")))

                student_model_ensemble.append(model)

    # Evaluate all student models from the ensemble
    eval_dataset = InMemoryDataset(images, preprocess)
    eval_loader = torch.utils.data.DataLoader(eval_dataset, batch_size=4, shuffle=False, num_workers=1,
                                              collate_fn=collate_fn, pin_memory=True)

    student_model_outputs = []
    for student_model in student_model_ensemble:
        student_model_output = evaluate(student_model, eval_loader, use_seed=True)
        student_model_outputs.append(student_model_output)

    # Generate some statistics
    # write_student_ensemble_statistics(teacher_model, images, student_model_outputs, preprocess, num_classes, collate_fn,
    #                                   model_saves_directory)

    return student_model_outputs


def _build_dataset_from_evaluating_model(teacher_model, train_images, preprocess, postprocess, preprocess_train,
                                         collate_fn, ignore_masks, temperature=1.0):
    """
    Takes train images in order to evaluate them on the teacher model.
    As a result, a `dataset` object from the type `InMemoryDataset` is created that includes the predictions from this
    model as the labels. Images in this dataset are the train images.
    """

    # `preprocess` will be set to the preprocessing function for model evaluation data
    train_eval_dataset = InMemoryDataset(train_images, preprocess)
    train_eval_loader = torch.utils.data.DataLoader(train_eval_dataset, batch_size=4, shuffle=False, num_workers=1,
                                                    collate_fn=collate_fn, pin_memory=True)

    teacher_outputs = evaluate(teacher_model, train_eval_loader, use_seed=True)

    # Apply miscalibration & train on softmax
    if temperature != 1.0:
        teacher_outputs = softmax(teacher_outputs / temperature, axis=1)

    if ignore_masks is not None:
        mask_with_channels = np.stack((ignore_masks, ignore_masks), axis=1)
        np.putmask(teacher_outputs, mask_with_channels, np.nan)

    # Prepare and apply postprocessing
    teacher_outputs = torch.tensor(teacher_outputs)
    if postprocess is not None:
        teacher_outputs = postprocess(teacher_outputs)

    teacher_outputs_data = [(train_images[i], teacher_outputs[i]) for i in range(len(train_images))]

    # Perform bagging
    bagged_data = []
    for image_and_label in teacher_outputs_data:
        if np.random.rand(1, 1) <= 1.0:
            bagged_data.append(image_and_label)

    teacher_outputs_dataset = InMemoryDataset(bagged_data, preprocess_train)

    return teacher_outputs_dataset


def _search_for_pretrained_students(directory, filename, num_students):
    """
    Searches for available pre-trained student models in a specified directory.
    Files for models should be called `<student-index>_student_<#epochs>_epochs.pt`.
    For example, `1_student_100_epochs.pt`.
    So `filename` will be this string, but without the student-index prefix (`student_<#epochs>_epochs.pt`).

    Parameters
    ----------
    directory : str
        Path to directory where the student models are in.
    filename : str
        Name of the state-dict file, of format `student_<#epochs>_epochs.pt`.
    num_students : int
        Size of the student model ensemble.

    Returns
    -------
    pretrained_students_available : bool
        A result stating whether a pre-trained student model ensemble was found for the specified path.
    """

    for i in range(num_students):
        model_saves_path = os.path.join(directory, f"{i + 1}_{filename}")
        if not os.path.exists(model_saves_path):
            return False
    return True
